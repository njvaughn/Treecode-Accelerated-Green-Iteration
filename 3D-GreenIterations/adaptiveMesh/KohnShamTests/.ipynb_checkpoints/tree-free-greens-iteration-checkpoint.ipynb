{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Missing libdevice file for compute_50.\nPlease ensure you have package cudatoolkit 7.5.\nInstall package by:\n\n    conda install cudatoolkit=7.5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a5fd7328cbd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mconvolution\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unable to import JIT GPU Convolutions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Greens-Functions-Iterative-Methods/3D-GreenIterations/adaptiveMesh/src/utilities/convolution.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# from hydrogenPotential import trueEnergy, trueWavefunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'void(float64[:,:], float64[:,:], float64[:], float64)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgpuHelmholtzConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsiNew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mglobalID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# identify the global ID of the thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/numba/cuda/decorators.py\u001b[0m in \u001b[0;36mkernel_jit\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m# Force compilation for the current context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mForce\u001b[0m \u001b[0mbinding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mcufunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcufunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mptx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;31m# Link\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0march\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnvvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_arch_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             ptx = nvvm.llvm_to_ptx(self.llvmir, opt=3, arch=arch,\n\u001b[0;32m--> 342\u001b[0;31m                                    **self._extra_options)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDUMP_ASSEMBLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/numba/cuda/cudadrv/nvvm.py\u001b[0m in \u001b[0;36mllvm_to_ptx\u001b[0;34m(llvmir, **opts)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mllvm_to_ptx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllvmir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mcu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompilationUnit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mlibdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'compute_20'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0;31m# New LLVM generate a shorthand for datalayout that NVVM does not know\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mllvmir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_replace_datalayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllvmir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/lsa/centos7/python-anaconda-arc-connect/created-20170421/lib/python3.5/site-packages/numba/cuda/cudadrv/nvvm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arch)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0march\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_closest_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mget_libdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMISSING_LIBDEVICE_FILE_MSG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_libdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Missing libdevice file for compute_50.\nPlease ensure you have package cudatoolkit 7.5.\nInstall package by:\n\n    conda install cudatoolkit=7.5\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "\n",
    "import os\n",
    "os.system('connectmod')\n",
    "os.system('module list')\n",
    "import sys\n",
    "import time\n",
    "import inspect\n",
    "sys.path.append('../src/dataStructures')\n",
    "sys.path.append('../src/utilities')\n",
    "sys.path.append('../ctypesTests/src')\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "from numba import cuda, jit, njit\n",
    "import time\n",
    "from scipy.optimize import root as scipyRoot\n",
    "from scipy.optimize.nonlin import BroydenFirst, KrylovJacobian\n",
    "from scipy.optimize.nonlin import InverseJacobian\n",
    "\n",
    "import densityMixingSchemes as densityMixing\n",
    "from fermiDiracDistribution import computeOccupations\n",
    "import resource\n",
    "sys.path.append('../ctypesTests')\n",
    "sys.path.append('../ctypesTests/lib')\n",
    "\n",
    "# from fixedPointFunctions import greensIteration_FixedPoint\n",
    "\n",
    "try: \n",
    "    from convolution import *\n",
    "except ImportError:\n",
    "    print('Unable to import JIT GPU Convolutions')\n",
    "try:\n",
    "    import directSumWrappers\n",
    "except ImportError:\n",
    "    print('Unable to import directSumWrappers due to ImportError')\n",
    "except OSError:\n",
    "    print('Unable to import directSumWrappers due to OSError')\n",
    "    \n",
    "try:\n",
    "    import treecodeWrappers\n",
    "except ImportError:\n",
    "    print('Unable to import treecodeWrapper due to ImportError')\n",
    "except OSError:\n",
    "    print('Unable to import treecodeWrapper due to OSError')\n",
    "\n",
    "\n",
    "global rootDirectory\n",
    "if os.uname()[1] == 'Nathans-MacBook-Pro.local':\n",
    "    rootDirectory = '/Users/nathanvaughn/Documents/GitHub/Greens-Functions-Iterative-Methods/3D-GreenIterations/adaptiveMesh/'\n",
    "else:\n",
    "    print('os.uname()[1] = ', os.uname()[1])\n",
    "\n",
    "import unittest\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import itertools\n",
    "import csv\n",
    "\n",
    "from TreeStruct_CC import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "\n",
    "def setUpTree(onlyFillOne=False):\n",
    "    '''\n",
    "    setUp() gets called before every test below.\n",
    "    '''\n",
    "    xmin = ymin = zmin = -domainSize\n",
    "    xmax = ymax = zmax = domainSize\n",
    "    \n",
    "    global referenceEigenvalues\n",
    "#     [coordinateFile, outputFile, nElectrons, nOrbitals] = np.genfromtxt(inputFile,dtype=[(str,str,int,int,float,float,float,float,float)])[0:4]\n",
    "\n",
    "#     [coordinateFile, outputFile, nElectrons, nOrbitals, \n",
    "#      Etotal, Eexchange, Ecorrelation, Eband, gaugeShift] = np.genfromtxt(inputFile,delimiter=',',dtype=[(\"|U100\",\"|U100\",int,int,float,float,float,float,float)])\n",
    "    [coordinateFile, referenceEigenvaluesFile, DummyOutputFile] = np.genfromtxt(inputFile,dtype=\"|U100\")[:3]\n",
    "#     [nElectrons, nOrbitals, Eband, Ekinetic, Eexchange, Ecorrelation, Eelectrostatic, Etotal, gaugeShift] = np.genfromtxt(inputFile)[2:]\n",
    "    [Eband, Ekinetic, Eexchange, Ecorrelation, Eelectrostatic, Etotal] = np.genfromtxt(inputFile)[3:]\n",
    "#     nElectrons = int(nElectrons)\n",
    "#     nOrbitals = int(nOrbitals)\n",
    "    \n",
    "#     nOrbitals = 7  # hard code this in for Carbon Monoxide\n",
    "#     print('Hard coding nOrbitals to 7')\n",
    " #     nOrbitals = 6\n",
    "#     print('Hard coding nOrbitals to 6 to give oxygen one extra')\n",
    "#     nOrbitals = 1\n",
    "#     print('Hard coding nOrbitals to 1')\n",
    "\n",
    "    print('Reading atomic coordinates from: ', coordinateFile)\n",
    "    atomData = np.genfromtxt(coordinateFile,delimiter=',',dtype=float)\n",
    "    print(atomData)\n",
    "    if np.shape(atomData)==(5,):\n",
    "        nElectrons = atomData[3]\n",
    "    else:\n",
    "        nElectrons = 0\n",
    "        for i in range(len(atomData)):\n",
    "            nElectrons += atomData[i,3]\n",
    "    \n",
    "    nOrbitals = int( np.ceil(nElectrons/2)  )   # start with the minimum number of orbitals \n",
    "#     nOrbitals = int( np.ceil(nElectrons/2) + 1 )   # start with the minimum number of orbitals plus 1.  \n",
    "                                            # If the final orbital is unoccupied, this amount is enough. \n",
    "                                            # If there is a degeneracy leading to teh final orbital being \n",
    "                                            # partially filled, then it will be necessary to increase nOrbitals by 1.\n",
    "                        \n",
    "    # For O2, init 10 orbitals.\n",
    "#     nOrbitals=10                    \n",
    "\n",
    "    occupations = 2*np.ones(nOrbitals)\n",
    "#     nOrbitals=7\n",
    "#     print('Setting nOrbitals to six for purposes of testing the adaptivity on the oxygen atom.')\n",
    "#     print('Setting nOrbitals to seven for purposes of running Carbon monoxide.')\n",
    "    \n",
    "    \n",
    "#     nOrbitals = 6\n",
    "\n",
    "    if inputFile=='../src/utilities/molecularConfigurations/oxygenAtomAuxiliary.csv':\n",
    "        nOrbitals=5\n",
    "        occupations = 2*np.ones(nOrbitals)\n",
    "        occupations[2] = 4/3\n",
    "        occupations[3] = 4/3\n",
    "        occupations[4] = 4/3\n",
    "        \n",
    "    elif inputFile=='../src/utilities/molecularConfigurations/benzeneAuxiliary.csv':\n",
    "        nOrbitals=22\n",
    "        occupations = 2*np.ones(nOrbitals)\n",
    "        occupations[-1]=0\n",
    "#         occupations = [2, 2, 2/3 ,2/3 ,2/3, \n",
    "#                        2, 2, 2/3 ,2/3 ,2/3,\n",
    "#                        2, 2, 2/3 ,2/3 ,2/3,\n",
    "#                        2, 2, 2/3 ,2/3 ,2/3,\n",
    "#                        2, 2, 2/3 ,2/3 ,2/3,\n",
    "#                        2, 2, 2/3 ,2/3 ,2/3, \n",
    "#                        1,\n",
    "#                        1,\n",
    "#                        1,\n",
    "#                        1,\n",
    "#                        1,\n",
    "#                        1]\n",
    "        \n",
    "    elif inputFile=='../src/utilities/molecularConfigurations/O2Auxiliary.csv':\n",
    "        nOrbitals=10\n",
    "        occupations = [2,2,2,2,4/3,4/3,4/3,4/3,4/3,4/3]\n",
    "        \n",
    "    elif inputFile=='../src/utilities/molecularConfigurations/carbonMonoxideAuxiliary.csv':\n",
    "#         nOrbitals=10\n",
    "#         occupations = [2, 2, 4/3 ,4/3 ,4/3, \n",
    "#                        2, 2, 2/3 ,2/3 ,2/3 ]\n",
    "        nOrbitals=7\n",
    "        occupations = 2*np.ones(nOrbitals)\n",
    "    \n",
    "    elif inputFile=='../src/utilities/molecularConfigurations/hydrogenMoleculeAuxiliary.csv':\n",
    "        nOrbitals=1\n",
    "        occupations = [2]\n",
    "        \n",
    "    print('in testBatchGreen..., nOrbitals = ', nOrbitals)\n",
    "    \n",
    "    print([coordinateFile, outputFile, nElectrons, nOrbitals, \n",
    "     Etotal, Eexchange, Ecorrelation, Eband, gaugeShift])\n",
    "    \n",
    "    referenceEigenvalues = np.array( np.genfromtxt(referenceEigenvaluesFile,delimiter=',',dtype=float) )\n",
    "    print(referenceEigenvalues)\n",
    "    print(np.shape(referenceEigenvalues))\n",
    "    tree = Tree(xmin,xmax,order,ymin,ymax,order,zmin,zmax,order,nElectrons,nOrbitals,additionalDepthAtAtoms=additionalDepthAtAtoms,minDepth=minDepth,gaugeShift=gaugeShift,\n",
    "                coordinateFile=coordinateFile,smoothingEps=smoothingEps, inputFile=inputFile)#, iterationOutFile=outputFile)\n",
    "    tree.referenceEigenvalues = np.copy(referenceEigenvalues)\n",
    "    tree.occupations = occupations\n",
    "    print('On the tree, nOrbitals = ', tree.nOrbitals)\n",
    "    print('type: ', type(tree.nOrbitals))\n",
    "    \n",
    "    print('max depth ', maxDepth)\n",
    "    tree.buildTree( maxLevels=maxDepth, initializationType='atomic',divideCriterion=divideCriterion, \n",
    "                    divideParameter1=divideParameter1, divideParameter2=divideParameter2, divideParameter3=divideParameter3, divideParameter4=divideParameter4, \n",
    "                    savedMesh=savedMesh, restart=restart, printTreeProperties=True,onlyFillOne=onlyFillOne)\n",
    "\n",
    " \n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testGreenIterationsGPU_rootfinding(vtkExport=False,onTheFlyRefinement=False, maxOrbitals=None, maxSCFIterations=None, restartFile=None):\n",
    "    global tree\n",
    "    \n",
    "    startTime = time.time()\n",
    "    tree.E = -1.0 # set initial energy guess\n",
    "\n",
    "\n",
    "    numberOfTargets = tree.numberOfGridpoints                # set N to be the number of gridpoints.  These will be all the targets\n",
    "    \n",
    "    greenIterations_KohnSham_SCF_rootfinding(scfTolerance, energyTolerance, numberOfTargets, gradientFree, symmetricIteration, GPUpresent, treecode, treecodeOrder, theta, maxParNode, batchSize, \n",
    "                                 mixingScheme, mixingParameter, mixingHistoryCutoff,\n",
    "                                 subtractSingularity, gaussianAlpha,\n",
    "                                 inputFile=inputFile,outputFile=outputFile, restartFile=restart,\n",
    "                                 onTheFlyRefinement=onTheFlyRefinement, vtkExport=False, maxOrbitals=maxOrbitals, maxSCFIterations=maxSCFIterations)\n",
    "\n",
    "#     greenIterations_KohnSham_SINGSUB(tree, scfTolerance, energyTolerance, numberOfTargets, subtractSingularity, \n",
    "#                                 smoothingEps, gaussianAlpha,auxiliaryFile=auxiliaryFile, \n",
    "#                                 onTheFlyRefinement=onTheFlyRefinement, vtkExport=vtkExport)\n",
    "\n",
    "    totalKohnShamTime = time.time()-startTime\n",
    "    print('Total Time: ', totalKohnShamTime)\n",
    "\n",
    "    header = ['domainSize','minDepth','maxDepth','additionalDepthAtAtoms','depthAtAtoms','order','numberOfCells','numberOfPoints','gradientFree',\n",
    "              'divideCriterion','divideParameter1','divideParameter2','divideParameter3','divideParameter4',\n",
    "              'gaussianAlpha','gaugeShift','VextSmoothingEpsilon','energyTolerance',\n",
    "              'GreenSingSubtracted', 'orbitalEnergies', 'BandEnergy', 'KineticEnergy',\n",
    "              'ExchangeEnergy','CorrelationEnergy','HartreeEnergy','TotalEnergy',\n",
    "              'Treecode','treecodeOrder','theta','maxParNode','batchSize','totalTime','timePerConvolution','totalIterationCount']\n",
    "    \n",
    "    myData = [domainSize,tree.minDepthAchieved,tree.maxDepthAchieved,tree.additionalDepthAtAtoms,tree.maxDepthAtAtoms,tree.px,tree.numberOfCells,tree.numberOfGridpoints,gradientFree,\n",
    "              divideCriterion,divideParameter1,divideParameter2,divideParameter3,divideParameter4,\n",
    "              gaussianAlpha,gaugeShift,smoothingEps,energyTolerance,\n",
    "              subtractSingularity,\n",
    "              tree.orbitalEnergies-tree.gaugeShift, tree.totalBandEnergy, tree.totalKinetic, tree.totalEx, tree.totalEc, tree.totalEhartree, tree.E,\n",
    "              treecode,treecodeOrder,theta,maxParNode,batchSize, totalKohnShamTime,tree.timePerConvolution,tree.totalIterationCount]\n",
    "#               tree.E, tree.\n",
    "#               tree.E, tree.orbitalEnergies[0], abs(tree.E+1.1373748), abs(tree.orbitalEnergies[0]+0.378665)]\n",
    "    \n",
    "\n",
    "    runComparisonFile = os.path.split(outputFile)[0] + '/runComparison.csv'\n",
    "    \n",
    "    if not os.path.isfile(runComparisonFile):\n",
    "        myFile = open(runComparisonFile, 'a')\n",
    "        with myFile:\n",
    "            writer = csv.writer(myFile)\n",
    "            writer.writerow(header) \n",
    "        \n",
    "        \n",
    "    \n",
    "    myFile = open(runComparisonFile, 'a')\n",
    "    with myFile:\n",
    "        writer = csv.writer(myFile)\n",
    "        writer.writerow(myData)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Norm / Orthogonalization Functions\n",
    "@jit(parallel=True)\n",
    "def modifiedGramSchrmidt(V,weights):\n",
    "    n,k = np.shape(V)\n",
    "    U = np.zeros_like(V)\n",
    "    U[:,0] = V[:,0] / np.dot(V[:,0],V[:,0]*weights)\n",
    "    for i in range(1,k):\n",
    "        U[:,i] = V[:,i]\n",
    "        for j in range(i):\n",
    "#             print('Orthogonalizing %i against %i' %(i,j))\n",
    "            U[:,i] -= (np.dot(U[:,i],U[:,j]*weights) / np.dot(U[:,j],U[:,j]*weights))*U[:,j]\n",
    "        U[:,i] /= np.dot(U[:,i],U[:,i]*weights)\n",
    "        \n",
    "    return U\n",
    "\n",
    "@jit()\n",
    "def modifiedGramSchmidt_singleOrbital(V,weights,targetOrbital, n, k):\n",
    "    U = V[:,targetOrbital]\n",
    "    for j in range(targetOrbital):\n",
    "#         print('Orthogonalizing %i against %i' %(targetOrbital,j))\n",
    "#         U -= (np.dot(V[:,targetOrbital],V[:,j]*weights) / np.dot(V[:,j],V[:,j]*weights))*V[:,j]\n",
    "        U -= np.dot(V[:,targetOrbital],V[:,j]*weights) *V[:,j]\n",
    "        U /= np.sqrt( np.dot(U,U*weights) )\n",
    "    \n",
    "    U /= np.sqrt( np.dot(U,U*weights) )  # normalize again at end (safegaurd for the zeroth orbital, which doesn't enter the above loop)\n",
    "        \n",
    "    return U\n",
    "\n",
    "def modifiedGramSchrmidt_noNormalization(V,weights):\n",
    "    n,k = np.shape(V)\n",
    "    U = np.zeros_like(V)\n",
    "    U[:,0] = V[:,0] \n",
    "    for i in range(1,k):\n",
    "        U[:,i] = V[:,i]\n",
    "        for j in range(i):\n",
    "            print('Orthogonalizing %i against %i' %(i,j))\n",
    "            U[:,i] -= (np.dot(U[:,i],U[:,j]*weights) / np.dot(U[:,j],U[:,j]*weights))*U[:,j]\n",
    "#         U[:,i] /= np.dot(U[:,i],U[:,i]*weights)\n",
    "        \n",
    "    return U\n",
    "\n",
    "def normalizeOrbitals(V,weights):\n",
    "    print('Only normalizing, not orthogonalizing orbitals')\n",
    "    n,k = np.shape(V)\n",
    "    U = np.zeros_like(V)\n",
    "#     U[:,0] = V[:,0] / np.dot(V[:,0],V[:,0]*weights)\n",
    "    for i in range(0,k):\n",
    "        U[:,i]  = V[:,i]\n",
    "        U[:,i] /= np.sqrt( np.dot(U[:,i],U[:,i]*weights) )\n",
    "        \n",
    "        if abs( 1- np.dot(U[:,i],U[:,i]*weights)) > 1e-12:\n",
    "            print('orbital ', i, ' not normalized? Should be 1: ', np.dot(U[:,i],U[:,i]*weights))\n",
    "    \n",
    "    return U\n",
    "\n",
    "def clenshawCurtisNorm(psi):\n",
    "#     return np.max(np.abs(psi))\n",
    "#     print('USING CLENSHAW CURTIS NORM CALLED BY ', inspect.stack()[2][3])\n",
    "# #     return np.sqrt(np.sum(psi*psi))\n",
    "# #     global weights\n",
    "#      \n",
    "    appendedWeights = np.append(weights, 10.0)\n",
    "#     print(appendedWeights[-5:])\n",
    "    norm = np.sqrt( np.sum( psi*psi*appendedWeights ) )\n",
    "#     print('Norm = ', norm)\n",
    "    return norm\n",
    "\n",
    "def eigenvalueNorm(psi):\n",
    "    norm = np.sqrt( psi[-1]**2 )\n",
    "    return norm\n",
    "\n",
    "\n",
    "def clenshawCurtisNorm_withoutEigenvalue(psi):\n",
    "    return np.sqrt( np.sum( psi*psi*weights ) )\n",
    "\n",
    "def printResidual(x,f):\n",
    "    r = clenshawCurtisNorm(f)\n",
    "#     r = np.sqrt( np.sum(f*f*weights) )\n",
    "    print('L2 Norm of Residual: ', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greensIteration_FixedPoint(psiIn):\n",
    "    print('Who called F(x)? ', inspect.stack()[2][3])\n",
    "    inputWave = np.copy(psiIn[:-1])\n",
    "#     print('Norm of psiIn:', clenshawCurtisNorm_withoutEigenvalue(inputWave))\n",
    "#     print('Norm of psiIn - what was already in orbitals array: ', clenshawCurtisNorm_withoutEigenvalue(inputWave-orbitals[:,m]))\n",
    "#     print('Norm of psiIn - what was already in oldOrbitals array: ', clenshawCurtisNorm_withoutEigenvalue(inputWave-oldOrbitals[:,m]))\n",
    "    \n",
    "#     psiIn /= clenshawCurtisNorm(psiIn)\n",
    "#     print('Normalizing psiIn...')\n",
    "#     print('Norm of psiIn - what was already in orbitals array: ', clenshawCurtisNorm(psiIn-orbitals[:,m]))\n",
    "#     print('Norm of psiIn - what was already in oldOrbitals array: ', clenshawCurtisNorm(psiIn-oldOrbitals[:,m]))\n",
    "    # global data structures\n",
    "    global tree, orbitals, oldOrbitals, residuals, eigenvalueHistory\n",
    "    \n",
    "    # Global constants and counters\n",
    "    global threadsPerBlock, blocksPerGrid, SCFcount, greenIterationsCount\n",
    "    global greenIterationOutFile\n",
    "    \n",
    "#     if inspect.stack()[2][3]=='nonlin_solve':\n",
    "    if True:\n",
    "        tree.totalIterationCount += 1\n",
    "        \n",
    "        \n",
    "        oldOrbitals[:,m] = np.copy(psiIn[:-1])    \n",
    "        orbitals[:,m] = np.copy(psiIn[:-1])\n",
    "        n,M = np.shape(orbitals)\n",
    "        orthWavefunction = modifiedGramSchmidt_singleOrbital(orbitals,weights,m, n, M)\n",
    "        orbitals[:,m] = np.copy(orthWavefunction)\n",
    "        tree.importPhiOnLeaves(orbitals[:,m], m)\n",
    "        tree.orbitalEnergies[m] = np.copy(psiIn[-1])\n",
    "    else:\n",
    "#         print('Different function called F(x), not updating tree.')\n",
    "        print('Not updating tree.')\n",
    "\n",
    "#     tree.importPhiOnLeaves(oldOrbitals[:,m], m)\n",
    "# #     oldOrbitals[:,m] = np.copy(orbitals[:,m])\n",
    "    \n",
    "#     targets = tree.extractPhi(m)\n",
    "#     sources = np.copy(targets)\n",
    "\n",
    "\n",
    "    if symmetricIteration==False:\n",
    "        sources = tree.extractGreenIterationIntegrand(m)\n",
    "#         sources = tree.extractGreenIterationIntegrand_Deflated(m,orbitals,weights)\n",
    "    elif symmetricIteration == True:\n",
    "#                     sources = tree.extractGreenIterationIntegrand_Deflated(m,orbitals,weights)\n",
    "        sources, sqrtV = tree.extractGreenIterationIntegrand_symmetric(m)\n",
    "    else: \n",
    "        print(\"symmetricIteration variable not True or False.  What should it be?\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    targets=np.copy(sources)\n",
    "\n",
    "\n",
    "\n",
    "    oldEigenvalue =  tree.orbitalEnergies[m] \n",
    "    k = np.sqrt(-2*tree.orbitalEnergies[m])\n",
    "\n",
    "    phiNew = np.zeros((len(targets)))\n",
    "    if subtractSingularity==0: \n",
    "        print('Using singularity skipping')\n",
    "        gpuHelmholtzConvolution[blocksPerGrid, threadsPerBlock](targets,sources,phiNew,k) \n",
    "    elif subtractSingularity==1:\n",
    "        if tree.orbitalEnergies[m] < 10.25**100: \n",
    "            \n",
    "            \n",
    "            if GPUpresent==False:\n",
    "                print('Using Precompiled-C Helmholtz Singularity Subtract')\n",
    "                numTargets = len(targets)\n",
    "                numSources = len(sources)\n",
    "\n",
    "                sourceX = np.copy(sources[:,0])\n",
    "\n",
    "                sourceY = np.copy(sources[:,1])\n",
    "                sourceZ = np.copy(sources[:,2])\n",
    "                sourceValue = np.copy(sources[:,3])\n",
    "                sourceWeight = np.copy(sources[:,4])\n",
    "                \n",
    "                targetX = np.copy(targets[:,0])\n",
    "                targetY = np.copy(targets[:,1])\n",
    "                targetZ = np.copy(targets[:,2])\n",
    "                targetValue = np.copy(targets[:,3])\n",
    "                targetWeight = np.copy(targets[:,4])\n",
    "                \n",
    "                phiNew = directSumWrappers.callCompiledC_directSum_HelmholtzSingularitySubtract(numTargets, numSources, k, \n",
    "                                                                                                      targetX, targetY, targetZ, targetValue, targetWeight, \n",
    "                                                                                                      sourceX, sourceY, sourceZ, sourceValue, sourceWeight)\n",
    "                phiNew += 4*np.pi*targets[:,3]/k**2\n",
    "\n",
    "\n",
    "                phiNew /= (4*np.pi)\n",
    "            elif GPUpresent==True:\n",
    "                if treecode==False:\n",
    "                    startTime = time.time()\n",
    "                    if symmetricIteration==False:\n",
    "                        gpuHelmholtzConvolutionSubractSingularity[blocksPerGrid, threadsPerBlock](targets,sources,phiNew,k) \n",
    "                        convolutionTime = time.time()-startTime\n",
    "                        print('Using asymmetric singularity subtraction.  Convolution time: ', convolutionTime)\n",
    "                    elif symmetricIteration==True:\n",
    "                        gpuHelmholtzConvolutionSubractSingularitySymmetric[blocksPerGrid, threadsPerBlock](targets,sources,sqrtV,phiNew,k) \n",
    "                        phiNew *= -1\n",
    "                        convolutionTime = time.time()-startTime\n",
    "                        print('Using symmetric singularity subtraction.  Convolution time: ', convolutionTime)\n",
    "                    convTime=time.time()-startTime\n",
    "                    print('Convolution time: ', convTime)\n",
    "                    tree.timePerConvolution = convTime\n",
    "                    \n",
    "                elif treecode==True:\n",
    "                    \n",
    "                    copyStart = time.time()\n",
    "                    numTargets = len(targets)\n",
    "                    numSources = len(sources)\n",
    "\n",
    "                    sourceX = np.copy(sources[:,0])\n",
    "\n",
    "                    sourceY = np.copy(sources[:,1])\n",
    "                    sourceZ = np.copy(sources[:,2])\n",
    "                    sourceValue = np.copy(sources[:,3])\n",
    "                    sourceWeight = np.copy(sources[:,4])\n",
    "                    \n",
    "                    targetX = np.copy(targets[:,0])\n",
    "                    targetY = np.copy(targets[:,1])\n",
    "                    targetZ = np.copy(targets[:,2])\n",
    "                    targetValue = np.copy(targets[:,3])\n",
    "                    targetWeight = np.copy(targets[:,4])\n",
    "                \n",
    "                    copytime=time.time()-copyStart\n",
    "#                                         print('Time spent copying arrays for treecode call: ', copytime)\n",
    "                    \n",
    "                    potentialType=3\n",
    "                    kappa = k\n",
    "                    startTime = time.time()\n",
    "                    phiNew = treecodeWrappers.callTreedriver(numTargets, numSources, \n",
    "                                                                   targetX, targetY, targetZ, targetValue, \n",
    "                                                                   sourceX, sourceY, sourceZ, sourceValue, sourceWeight,\n",
    "                                                                   potentialType, kappa, treecodeOrder, theta, maxParNode, batchSize)\n",
    "                    convTime=time.time()-startTime\n",
    "                    print('Convolution time: ', convTime)\n",
    "                    tree.timePerConvolution = convTime\n",
    "                    phiNew /= (4*np.pi)\n",
    "                \n",
    "                else: \n",
    "                    print('treecode true or false?')\n",
    "                    return\n",
    "        else:\n",
    "            print('Using singularity skipping because energy too close to 0')\n",
    "            gpuHelmholtzConvolution[blocksPerGrid, threadsPerBlock](targets,sources,phiNew,k)\n",
    "    else:\n",
    "        print('Invalid option for singularitySubtraction, should be 0 or 1.')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \"\"\" Method where you dont compute kinetics, from Harrison \"\"\"\n",
    "    \n",
    "    # update the energy first\n",
    "    \n",
    "\n",
    "#     if ( (gradientFree==True) and (SCFcount>-1) and False):                 \n",
    "    if ( (gradientFree==True) and (SCFcount>-1)):                 \n",
    "        \n",
    "        psiNewNorm = np.sqrt( np.sum( phiNew*phiNew*weights))\n",
    "        \n",
    "        if symmetricIteration==False:\n",
    "            tree.importPhiNewOnLeaves(phiNew)\n",
    "#                                 print('Not updating energy, just for testing Steffenson method')\n",
    "            tree.updateOrbitalEnergies_NoGradients(m, newOccupations=False)\n",
    "            orbitals[:,m] = np.copy(phiNew)\n",
    "        elif symmetricIteration==True:\n",
    "#                                 tree.importPhiNewOnLeaves(phiNew/sqrtV)\n",
    "#                                 tree.updateOrbitalEnergies_NoGradients(m, newOccupations=False)\n",
    "\n",
    "\n",
    "            # import phiNew and compute eigenvalue update\n",
    "            tree.importPhiNewOnLeaves(phiNew)\n",
    "            tree.updateOrbitalEnergies_NoGradients(m, newOccupations=False, symmetric=True)\n",
    "            \n",
    "            # Import normalized psi*sqrtV into phiOld\n",
    "            phiNew /= np.sqrt( np.sum(phiNew*phiNew*weights ))\n",
    "            tree.setPhiOldOnLeaves_symmetric(phiNew)\n",
    "            \n",
    "            \n",
    "            orbitals[:,m] = np.copy(phiNew/sqrtV)\n",
    "        \n",
    "        n,M = np.shape(orbitals)\n",
    "#         print('Not orthgonoalizing, relying on deflation instead... (640)')\n",
    "        orthWavefunction = modifiedGramSchmidt_singleOrbital(orbitals,weights,m, n, M)\n",
    "        orbitals[:,m] = np.copy(orthWavefunction)\n",
    "        tree.importPhiOnLeaves(orbitals[:,m], m)\n",
    "        \n",
    "\n",
    "\n",
    "        if greenIterationsCount==1:\n",
    "            eigenvalueHistory = np.array(tree.orbitalEnergies[m])\n",
    "        else:\n",
    "            \n",
    "            eigenvalueHistory = np.append(eigenvalueHistory, tree.orbitalEnergies[m])\n",
    "        print('eigenvalueHistory: \\n',eigenvalueHistory)\n",
    "        \n",
    "        \n",
    "        print('Orbital energy after Harrison update: ', tree.orbitalEnergies[m])\n",
    "         \n",
    "\n",
    "#     elif ( (gradientFree==False) or (SCFcount==-1) and False ):\n",
    "    elif ( (gradientFree==False) or (gradientFree=='Laplacian') ):\n",
    "        \n",
    "        # update the orbital\n",
    "        if symmetricIteration==False:\n",
    "            orbitals[:,m] = np.copy(phiNew)\n",
    "        if symmetricIteration==True:\n",
    "            orbitals[:,m] = np.copy(phiNew/sqrtV)\n",
    "            \n",
    "        n,M = np.shape(orbitals)\n",
    "        orthWavefunction = modifiedGramSchmidt_singleOrbital(orbitals,weights,m, n, M)\n",
    "        orbitals[:,m] = np.copy(orthWavefunction)\n",
    "        tree.importPhiOnLeaves(orbitals[:,m], m)\n",
    "        \n",
    "#                             tree.importPhiOnLeaves(orbitals[:,m], m)\n",
    "#                             tree.orthonormalizeOrbitals(targetOrbital=m)\n",
    "        \n",
    "        tree.updateOrbitalEnergies(laplacian=gradientFree,sortByEnergy=False, targetEnergy=m)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print('Not updating eigenvalue.  Is that intended?')\n",
    "#                             print('Invalid option for gradientFree, which is set to: ', gradientFree)\n",
    "#                             print('type: ', type(gradientFree))\n",
    "\n",
    "        if greenIterationsCount==1:\n",
    "            eigenvalueHistory = np.array(tree.orbitalEnergies[m])\n",
    "        else:\n",
    "            \n",
    "            eigenvalueHistory = np.append(eigenvalueHistory, tree.orbitalEnergies[m])\n",
    "        print('eigenvalueHistory: \\n',eigenvalueHistory)\n",
    "        \n",
    "        orbitals[:,m] = np.copy(phiNew)\n",
    "        n,M = np.shape(orbitals)\n",
    "        orthWavefunction = modifiedGramSchmidt_singleOrbital(orbitals,weights,m, n, M)\n",
    "        orbitals[:,m] = np.copy(orthWavefunction)\n",
    "        \n",
    "        \n",
    "        tree.importPhiOnLeaves(orbitals[:,m], m)\n",
    "        tree.setPhiOldOnLeaves(m)\n",
    "        \n",
    "       \n",
    "        eigenvalueHistory = np.append(eigenvalueHistory, tree.orbitalEnergies[m])\n",
    "    \n",
    "    \n",
    "    if tree.orbitalEnergies[m]>0.0:\n",
    "        tree.orbitalEnergies[m] = tree.gaugeShift - 0.5\n",
    "        print('Energy eigenvalue was positive, setting to gauge shift - 0.5')\n",
    "        \n",
    "    tempOrbital = tree.extractPhi(m)\n",
    "    orbitals[:,m] = np.copy( tempOrbital[:,3] )\n",
    "    \n",
    "    \n",
    "    tree.printWavefunctionNearEachAtom(m)\n",
    "        \n",
    "#     residualVector = orbitals[:,m] - oldOrbitals[:,m]\n",
    "    psiOut = np.append(np.copy(orbitals[:,m]), np.copy(tree.orbitalEnergies[m]))\n",
    "    residualVector = psiOut - psiIn\n",
    "    \n",
    "    \n",
    "    \n",
    "    loc = np.argmax(np.abs(residualVector[:-1]))\n",
    "    print('Largest residual: ', residualVector[loc])\n",
    "    print('Value at that point: ', psiOut[loc])\n",
    "    print('Location of max residual: ', tempOrbital[loc,0], tempOrbital[loc,1], tempOrbital[loc,2])\n",
    "#     residualVector = -(psiIn - orbitals[:,m])\n",
    "\n",
    "    newEigenvalue = tree.orbitalEnergies[m]\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    if symmetricIteration==False:\n",
    "        normDiff = np.sqrt( np.sum( (orbitals[:,m]-oldOrbitals[:,m])**2*weights ) )\n",
    "    elif symmetricIteration==True:\n",
    "        normDiff = np.sqrt( np.sum( (orbitals[:,m]*sqrtV-oldOrbitals[:,m]*sqrtV)**2*weights ) )\n",
    "    eigenvalueDiff = abs(newEigenvalue - oldEigenvalue)\n",
    "    \n",
    "    tree.eigenvalueDiff = eigenvalueDiff\n",
    "    \n",
    "    \n",
    "\n",
    "    residuals[m] = normDiff\n",
    "    orbitalResidual = np.copy(normDiff)\n",
    "    \n",
    "    \n",
    "\n",
    "    print('Orbital %i error and eigenvalue residual:   %1.3e and %1.3e' %(m,tree.orbitalEnergies[m]-tree.referenceEigenvalues[m]-tree.gaugeShift, eigenvalueDiff))\n",
    "    print('Orbital %i wavefunction residual: %1.3e' %(m, orbitalResidual))\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "    header = ['targetOrbital', 'Iteration', 'orbitalResiduals', 'energyEigenvalues', 'eigenvalueResidual']\n",
    "\n",
    "    myData = [m, greenIterationsCount, residuals,\n",
    "              tree.orbitalEnergies-tree.gaugeShift, eigenvalueDiff]\n",
    "\n",
    "    if not os.path.isfile(greenIterationOutFile):\n",
    "        myFile = open(greenIterationOutFile, 'a')\n",
    "        with myFile:\n",
    "            writer = csv.writer(myFile)\n",
    "            writer.writerow(header) \n",
    "        \n",
    "    \n",
    "    myFile = open(greenIterationOutFile, 'a')\n",
    "    with myFile:\n",
    "        writer = csv.writer(myFile)\n",
    "        writer.writerow(myData)\n",
    "    \n",
    "      \n",
    "    greenIterationsCount += 1\n",
    "    return residualVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greenIterations_KohnSham_SCF_rootfinding(intraScfTolerance, interScfTolerance, numberOfTargets, gradientFree, symmetricIteration, GPUpresent, \n",
    "                                 treecode, treecodeOrder, theta, maxParNode, batchSize,\n",
    "                                 mixingScheme, mixingParameter, mixingHistoryCutoff,\n",
    "                                subtractSingularity, gaussianAlpha, inputFile='',outputFile='',restartFile=False,\n",
    "                                onTheFlyRefinement = False, vtkExport=False, outputErrors=False, maxOrbitals=None, maxSCFIterations=None): \n",
    "    '''\n",
    "    Green Iterations for Kohn-Sham DFT using Clenshaw-Curtis quadrature.\n",
    "    '''\n",
    "    global tree, weights\n",
    "    global threadsPerBlock, blocksPerGrid, SCFcount, greenIterationsCount, m\n",
    "    global greenIterationOutFile\n",
    "    global orbitals, oldOrbitals\n",
    "    \n",
    "    \n",
    "#     return\n",
    "    print('MEMORY USAGE: ', resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "    print()\n",
    "\n",
    "\n",
    "    if hasattr(tree, 'referenceEigenvalues'):\n",
    "        referenceEigenvalues = tree.referenceEigenvalues\n",
    "    else:\n",
    "        print('Tree did not have attribute referenceEigenvalues')\n",
    "        referenceEigenvalues = np.zeros(tree.nOrbitals)\n",
    "        return\n",
    "    \n",
    "    # Store Tree variables locally\n",
    "    numberOfGridpoints = tree.numberOfGridpoints\n",
    "    gaugeShift = tree.gaugeShift\n",
    "    Temperature = 200  # set to 200 Kelvin\n",
    "    \n",
    "    \n",
    "\n",
    "    greenIterationOutFile = outputFile[:-4]+'_GREEN_'+str(tree.numberOfGridpoints)+outputFile[-4:]\n",
    "    SCFiterationOutFile =   outputFile[:-4]+'_SCF_'+str(tree.numberOfGridpoints)+outputFile[-4:]\n",
    "    densityPlotsDir =       outputFile[:-4]+'_SCF_'+str(tree.numberOfGridpoints)+'_plots'\n",
    "    restartFilesDir =       '/home/njvaughn/restartFiles/'+'restartFiles_'+str(tree.numberOfGridpoints)\n",
    "#     restartFilesDir =       '/home/njvaughn/restartFiles/restartFiles_1416000_after25'\n",
    "#     restartFilesDir =       '/Users/nathanvaughn/Documents/synchronizedDataFiles/restartFiles_1416000_after25'\n",
    "    wavefunctionFile =      restartFilesDir+'/wavefunctions'\n",
    "    densityFile =           restartFilesDir+'/density'\n",
    "    inputDensityFile =      restartFilesDir+'/inputdensity'\n",
    "    outputDensityFile =     restartFilesDir+'/outputdensity'\n",
    "    vHartreeFile =          restartFilesDir+'/vHartree'\n",
    "    auxiliaryFile =         restartFilesDir+'/auxiliary'\n",
    "    \n",
    "    plotSliceOfDensity=False\n",
    "    if plotSliceOfDensity==True:\n",
    "        try:\n",
    "            os.mkdir(densityPlotsDir)\n",
    "        except OSError:\n",
    "            print('Unable to make directory ', densityPlotsDir)\n",
    "        \n",
    "    try:\n",
    "        os.mkdir(restartFilesDir)\n",
    "    except OSError:\n",
    "        print('Unable to make restart directory ', restartFilesDir)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if maxOrbitals==1:\n",
    "        nOrbitals = 1\n",
    "    else:\n",
    "        nOrbitals = tree.nOrbitals\n",
    "            \n",
    "    if restartFile!=False:\n",
    "        global orbitals, oldOrbitals\n",
    "        orbitals = np.load(wavefunctionFile+'.npy')\n",
    "        oldOrbitals = np.copy(orbitals)\n",
    "        for m in range(nOrbitals): \n",
    "            tree.importPhiOnLeaves(orbitals[:,m], m)\n",
    "        density = np.load(densityFile+'.npy')\n",
    "        tree.importDensityOnLeaves(density)\n",
    "        \n",
    "        inputDensities = np.load(inputDensityFile+'.npy')\n",
    "        outputDensities = np.load(outputDensityFile+'.npy')\n",
    "        \n",
    "        V_hartreeNew = np.load(vHartreeFile+'.npy')\n",
    "        tree.importVhartreeOnLeaves(V_hartreeNew)\n",
    "        tree.updateVxcAndVeffAtQuadpoints()\n",
    "        \n",
    "        \n",
    "        # make and save dictionary\n",
    "        auxiliaryRestartData = np.load(auxiliaryFile+'.npy').item()\n",
    "        print('type of aux: ', type(auxiliaryRestartData))\n",
    "        SCFcount = auxiliaryRestartData['SCFcount']\n",
    "        tree.totalIterationCount = auxiliaryRestartData['totalIterationCount']\n",
    "        tree.orbitalEnergies = auxiliaryRestartData['eigenvalues'] \n",
    "        Eold = auxiliaryRestartData['Eold']\n",
    "    \n",
    "    else: \n",
    "        Eold = -10\n",
    "        SCFcount=0\n",
    "        tree.totalIterationCount = 0\n",
    "        \n",
    "        # Initialize orbital matrix\n",
    "        targets = tree.extractLeavesDensity()\n",
    "\n",
    "        orbitals = np.zeros((len(targets),tree.nOrbitals))\n",
    "        oldOrbitals = np.zeros((len(targets),tree.nOrbitals))\n",
    "        \n",
    "          \n",
    "        for m in range(nOrbitals):\n",
    "            # fill in orbitals\n",
    "            targets = tree.extractPhi(m)\n",
    "            weights = np.copy(targets[:,5])\n",
    "            oldOrbitals[:,m] = np.copy(targets[:,3])\n",
    "            orbitals[:,m] = np.copy(targets[:,3])\n",
    "            \n",
    "        # Initialize density history arrays\n",
    "        inputDensities = np.zeros((numberOfGridpoints,1))\n",
    "        outputDensities = np.zeros((numberOfGridpoints,1))\n",
    "        \n",
    "        targets = tree.extractLeavesDensity() \n",
    "        weights = targets[:,4]\n",
    "        inputDensities[:,0] = np.copy(targets[:,3])\n",
    "\n",
    "    targets = tree.extractLeavesDensity() \n",
    "    weights = targets[:,4]\n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    if plotSliceOfDensity==True:\n",
    "        densitySliceSavefile = densityPlotsDir+'/densities'\n",
    "        print()\n",
    "        r, rho = tree.interpolateDensity(xi,yi,zi,xf,yf,zf, numpts, plot=False, save=False)\n",
    "        \n",
    "        densities = np.concatenate( (np.reshape(r, (numpts,1)), np.reshape(rho, (numpts,1))), axis=1)\n",
    "        np.save(densitySliceSavefile,densities)\n",
    "\n",
    "    \n",
    "    \n",
    "    threadsPerBlock = 512\n",
    "    blocksPerGrid = (numberOfTargets + (threadsPerBlock - 1)) // threadsPerBlock  # compute the number of blocks based on N and threadsPerBlock\n",
    "    \n",
    "    print('\\nEntering greenIterations_KohnSham_SCF()')\n",
    "    print('\\nNumber of targets:   ', numberOfTargets)\n",
    "    print('Threads per block:   ', threadsPerBlock)\n",
    "    print('Blocks per grid:     ', blocksPerGrid)\n",
    "    \n",
    "    densityResidual = 10                                   # initialize the densityResidual to something that fails the convergence tolerance\n",
    "\n",
    "#     [Etrue, ExTrue, EcTrue, Eband] = np.genfromtxt(inputFile,dtype=[(str,str,int,int,float,float,float,float,float)])[4:8]\n",
    "    [Eband, Ekinetic, Eexchange, Ecorrelation, Ehartree, Etotal] = np.genfromtxt(inputFile)[3:9]\n",
    "    print([Eband, Ekinetic, Eexchange, Ecorrelation, Ehartree, Etotal])\n",
    "\n",
    "    ### COMPUTE THE INITIAL HAMILTONIAN ###\n",
    "    density_targets = tree.extractLeavesDensity()  \n",
    "    density_sources = np.copy(density_targets)\n",
    "#     sources = tree.extractDenstiySecondaryMesh()   # extract density on secondary mesh\n",
    "\n",
    "    integratedDensity = np.sum( density_sources[:,3]*density_sources[:,4] )\n",
    "#     densityResidual = np.sqrt( np.sum( (sources[:,3]-oldDensity[:,3])**2*weights ) )\n",
    "    print('Integrated density: ', integratedDensity)\n",
    "\n",
    "#     starthartreeConvolutionTime = timer()\n",
    "#     alpha = gaussianAlpha\n",
    "    alphasq=gaussianAlpha*gaussianAlpha\n",
    "    \n",
    "    \n",
    "    if restartFile==False: # need to do initial Vhartree solve\n",
    "        print('Using Gaussian singularity subtraction, alpha = ', gaussianAlpha)\n",
    "        \n",
    "        print('GPUpresent set to ', GPUpresent)\n",
    "        print('Type: ', type(GPUpresent))\n",
    "        if GPUpresent==False:\n",
    "            numTargets = len(density_targets)\n",
    "            numSources = len(density_sources)\n",
    "    #         print('numTargets = ', numTargets)\n",
    "    #         print(targets[:10,:])\n",
    "    #         print('numSources = ', numSources)\n",
    "    #         print(sources[:10,:])\n",
    "            copystart = time.time()\n",
    "            sourceX = np.copy(density_sources[:,0])\n",
    "    #         print(np.shape(sourceX))\n",
    "    #         print('sourceX = ', sourceX[0:10])\n",
    "            sourceY = np.copy(density_sources[:,1])\n",
    "            sourceZ = np.copy(density_sources[:,2])\n",
    "            sourceValue = np.copy(density_sources[:,3])\n",
    "            sourceWeight = np.copy(density_sources[:,4])\n",
    "            \n",
    "            targetX = np.copy(density_targets[:,0])\n",
    "            targetY = np.copy(density_targets[:,1])\n",
    "            targetZ = np.copy(density_targets[:,2])\n",
    "            targetValue = np.copy(density_targets[:,3])\n",
    "            targetWeight = np.copy(density_targets[:,4])\n",
    "            copytime=time.time()-copystart\n",
    "            print('Copy time before convolution: ', copytime)\n",
    "            start = time.time()\n",
    "            \n",
    "            if treecode==False:\n",
    "                V_hartreeNew = directSumWrappers.callCompiledC_directSum_PoissonSingularitySubtract(numTargets, numSources, alphasq, \n",
    "                                                                                                      targetX, targetY, targetZ, targetValue,targetWeight, \n",
    "                                                                                                      sourceX, sourceY, sourceZ, sourceValue, sourceWeight)\n",
    "    \n",
    "                V_hartreeNew += targets[:,3]* (4*np.pi)/ alphasq/ 2   # Correct for exp(-r*r/alphasq)  # DONT TRUST\n",
    "    \n",
    "            elif treecode==True:\n",
    "                \n",
    "                \n",
    "    # #         V_hartreeNew += targets[:,3]* (4*np.pi)* alphasq/2  # Wrong\n",
    "    \n",
    "    \n",
    "    #         V_hartreeNew = directSumWrappers.callCompiledC_directSum_Poisson(numTargets, numSources, \n",
    "    #                                                                         targetX, targetY, targetZ, targetValue,targetWeight, \n",
    "    #                                                                         sourceX, sourceY, sourceZ, sourceValue, sourceWeight)\n",
    "    \n",
    "                potentialType=2 # shoud be 2 for Hartree w/ singularity subtraction.  Set to 0, 1, or 3 just to test other kernels quickly\n",
    "#                 alpha = gaussianAlpha\n",
    "                V_hartreeNew = treecodeWrappers.callTreedriver(numTargets, numSources, \n",
    "                                                               targetX, targetY, targetZ, targetValue, \n",
    "                                                               sourceX, sourceY, sourceZ, sourceValue, sourceWeight,\n",
    "                                                               potentialType, gaussianAlpha, treecodeOrder, theta, maxParNode, batchSize)\n",
    "                   \n",
    "                if potentialType==2:\n",
    "                    V_hartreeNew += targets[:,3]* (4*np.pi) / alphasq/2\n",
    "    \n",
    "            \n",
    "    #         print('First few terms of V_hartreeNew: ', V_hartreeNew[:8])\n",
    "            print('Convolution time: ', time.time()-start)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        elif GPUpresent==True:\n",
    "            if treecode==False:\n",
    "                V_hartreeNew = np.zeros((len(density_targets)))\n",
    "                start = time.time()\n",
    "                gpuHartreeGaussianSingularitySubract[blocksPerGrid, threadsPerBlock](density_targets,density_sources,V_hartreeNew,alphasq)\n",
    "                print('Convolution time: ', time.time()-start)\n",
    "    #             return\n",
    "            elif treecode==True:\n",
    "                copystart=time.time()\n",
    "                numTargets = len(density_targets)\n",
    "                numSources = len(density_sources)\n",
    "                sourceX = np.copy(density_sources[:,0])\n",
    "    \n",
    "                sourceY = np.copy(density_sources[:,1])\n",
    "                sourceZ = np.copy(density_sources[:,2])\n",
    "                sourceValue = np.copy(density_sources[:,3])\n",
    "                sourceWeight = np.copy(density_sources[:,4])\n",
    "                \n",
    "                targetX = np.copy(density_targets[:,0])\n",
    "                targetY = np.copy(density_targets[:,1])\n",
    "                targetZ = np.copy(density_targets[:,2])\n",
    "                targetValue = np.copy(density_targets[:,3])\n",
    "                targetWeight = np.copy(density_targets[:,4])\n",
    "                copytime = time.time()-copystart\n",
    "                print('Copy time before calling treecode: ', copytime)\n",
    "                start = time.time()\n",
    "                potentialType=2 \n",
    "                V_hartreeNew = treecodeWrappers.callTreedriver(numTargets, numSources, \n",
    "                                                               targetX, targetY, targetZ, targetValue, \n",
    "                                                               sourceX, sourceY, sourceZ, sourceValue, sourceWeight,\n",
    "                                                               potentialType, gaussianAlpha, treecodeOrder, theta, maxParNode, batchSize)\n",
    "                print('Convolution time: ', time.time()-start)\n",
    "                \n",
    "            else:\n",
    "                print('treecode True or False?')\n",
    "                return\n",
    "        \n",
    "    \n",
    "    #     hartreeConvolutionTime = timer() - starthartreeConvolutionTime\n",
    "    #     print('Computing Vhartree took:    %.4f seconds. ' %hartreeConvolutionTime)\n",
    "        tree.importVhartreeOnLeaves(V_hartreeNew)\n",
    "        tree.updateVxcAndVeffAtQuadpoints()\n",
    "        \n",
    "        \n",
    "        ### Write output files that will be used to test the Treecode evaluation ###\n",
    "    #     sourcesTXT = '/Users/nathanvaughn/Documents/testData/H2Sources.txt'\n",
    "    #     targetsTXT = '/Users/nathanvaughn/Documents/testData/H2Targets.txt'\n",
    "    #     hartreePotentialTXT = '/Users/nathanvaughn/Documents/testData/H2HartreePotential.txt'\n",
    "        \n",
    "    #     np.savetxt(sourcesTXT, sources)\n",
    "    #     np.savetxt(targetsTXT, targets[:,0:4])\n",
    "    #     np.savetxt(hartreePotentialTXT, V_hartreeNew)\n",
    "    #     \n",
    "    #     return\n",
    "    \n",
    "    \n",
    "        print('Update orbital energies after computing the initial Veff.  Save them as the reference values for each cell')\n",
    "        tree.updateOrbitalEnergies(sortByEnergy=False, saveAsReference=True)\n",
    "        tree.computeBandEnergy()\n",
    "        \n",
    "        tree.sortOrbitalsAndEnergies()\n",
    "        for m in range(nOrbitals):\n",
    "            # fill in orbitals\n",
    "            targets = tree.extractPhi(m)\n",
    "            weights = np.copy(targets[:,5])\n",
    "            oldOrbitals[:,m] = np.copy(targets[:,3])\n",
    "            orbitals[:,m] = np.copy(targets[:,3])\n",
    "        print('Orbital energies after initial sort: \\n', tree.orbitalEnergies)\n",
    "        print('Kinetic:   ', tree.orbitalKinetic)\n",
    "        print('Potential: ', tree.orbitalPotential)\n",
    "        tree.updateTotalEnergy(gradientFree=False)\n",
    "        \"\"\"\n",
    "    \n",
    "        Print results before SCF 1\n",
    "        \"\"\"\n",
    "    \n",
    "        print('Orbital Energies: ', tree.orbitalEnergies) \n",
    "    \n",
    "        print('Orbital Energy Errors after initialization: ', tree.orbitalEnergies-referenceEigenvalues[:tree.nOrbitals]-tree.gaugeShift)\n",
    "    \n",
    "        print('Updated V_x:                           %.10f Hartree' %tree.totalVx)\n",
    "        print('Updated V_c:                           %.10f Hartree' %tree.totalVc)\n",
    "        \n",
    "        print('Updated Band Energy:                   %.10f H, %.10e H' %(tree.totalBandEnergy, tree.totalBandEnergy-Eband) )\n",
    "    #     print('Updated Kinetic Energy:                 %.10f H, %.10e H' %(tree.totalKinetic, tree.totalKinetic-Ekinetic) )\n",
    "        print('Updated E_H:                            %.10f H, %.10e H' %(tree.totalEhartree, tree.totalEhartree-Ehartree) )\n",
    "        print('Updated E_x:                           %.10f H, %.10e H' %(tree.totalEx, tree.totalEx-Eexchange) )\n",
    "        print('Updated E_c:                           %.10f H, %.10e H' %(tree.totalEc, tree.totalEc-Ecorrelation) )\n",
    "    #     print('Updated totalElectrostatic:            %.10f H, %.10e H' %(tree.totalElectrostatic, tree.totalElectrostatic-Eelectrostatic))\n",
    "        print('Total Energy:                          %.10f H, %.10e H' %(tree.E, tree.E-Etotal))\n",
    "        \n",
    "        \n",
    "        \n",
    "        printInitialEnergies=True\n",
    "    \n",
    "        if printInitialEnergies==True:\n",
    "            header = ['Iteration', 'densityResidual', 'orbitalEnergies','bandEnergy', 'kineticEnergy', \n",
    "                      'exchangeEnergy', 'correlationEnergy', 'hartreeEnergy', 'totalEnergy']\n",
    "        \n",
    "            myData = [0, 1, tree.orbitalEnergies, tree.totalBandEnergy, tree.totalKinetic, \n",
    "                      tree.totalEx, tree.totalEc, tree.totalEhartree, tree.E]\n",
    "            \n",
    "        \n",
    "            if not os.path.isfile(SCFiterationOutFile):\n",
    "                myFile = open(SCFiterationOutFile, 'a')\n",
    "                with myFile:\n",
    "                    writer = csv.writer(myFile)\n",
    "                    writer.writerow(header) \n",
    "                \n",
    "            \n",
    "            myFile = open(SCFiterationOutFile, 'a')\n",
    "            with myFile:\n",
    "                writer = csv.writer(myFile)\n",
    "                writer.writerow(myData)\n",
    "    \n",
    "    \n",
    "        for m in range(tree.nOrbitals):\n",
    "            if tree.orbitalEnergies[m] > tree.gaugeShift:\n",
    "                tree.orbitalEnergies[m] = tree.gaugeShift - 1.0\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "#         if vtkExport != False:\n",
    "#             filename = vtkExport + '/mesh%03d'%(SCFcount-1) + '.vtk'\n",
    "#             tree.exportGridpoints(filename)\n",
    "            \n",
    "        \n",
    "    #     if GPUpresent==False:\n",
    "    #         print('Exiting after initialization because no GPU present.')\n",
    "    #         return\n",
    "\n",
    "    initialWaveData = tree.extractPhi(0)\n",
    "    initialPsi0 = np.copy(initialWaveData[:,3])\n",
    "    x = np.copy(initialWaveData[:,0])\n",
    "    y = np.copy(initialWaveData[:,1])\n",
    "    z = np.copy(initialWaveData[:,2])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    energyResidual=1\n",
    "    global residuals\n",
    "    residuals = 10*np.ones_like(tree.orbitalEnergies)\n",
    "    \n",
    "    while ( (densityResidual > interScfTolerance) or (energyResidual > interScfTolerance) ):  # terminate SCF when both energy and density are converged.\n",
    "        SCFcount += 1\n",
    "        print()\n",
    "        print()\n",
    "        print('\\nSCF Count ', SCFcount)\n",
    "        print('Orbital Energies: ', tree.orbitalEnergies)\n",
    "#         if SCFcount > 0:\n",
    "#             print('Exiting before first SCF (for testing initialized mesh accuracy)')\n",
    "#             return\n",
    "        \n",
    "        if SCFcount>1:\n",
    "            targets = tree.extractLeavesDensity()\n",
    "            \n",
    "#             if SCFcount < mixingHistoryCutoff:\n",
    "#             inputDensities = np.concatenate( (inputDensities, np.reshape(targets[:,3], (numberOfGridpoints,1))), axis=1)\n",
    "#             else:\n",
    "#                 inputDensities\n",
    "\n",
    "            if (SCFcount-1)<mixingHistoryCutoff:\n",
    "                inputDensities = np.concatenate( (inputDensities, np.reshape(targets[:,3], (numberOfGridpoints,1))), axis=1)\n",
    "                print('Concatenated inputDensity.  Now has shape: ', np.shape(inputDensities))\n",
    "            else:\n",
    "                print('Beyond mixingHistoryCutoff.  Replacing column ', (SCFcount-1)%mixingHistoryCutoff)\n",
    "#                                 print('Shape of oldOrbitals[:,m]: ', np.shape(oldOrbitals[:,m]))\n",
    "                inputDensities[:,(SCFcount-1)%mixingHistoryCutoff] = np.copy(targets[:,3])\n",
    "        \n",
    "     \n",
    "        \n",
    "    \n",
    "            \n",
    "        \n",
    "\n",
    "        for m in range(nOrbitals): \n",
    "            print('Working on orbital %i' %m)\n",
    "            print('MEMORY USAGE: ', resource.getrusage(resource.RUSAGE_SELF).ru_maxrss )\n",
    "            if m>=3:\n",
    "                print('Saving restart files for after the psi0 and psi1 complete.')\n",
    "                # save arrays \n",
    "                try:\n",
    "                    np.save(wavefunctionFile, orbitals)\n",
    "                     \n",
    "                    sources = tree.extractLeavesDensity()\n",
    "                    np.save(densityFile, sources[:,3])\n",
    "                    np.save(outputDensityFile, outputDensities)\n",
    "                    np.save(inputDensityFile, inputDensities)\n",
    "                     \n",
    "                    np.save(vHartreeFile, V_hartreeNew)\n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                    # make and save dictionary\n",
    "                    auxiliaryRestartData = {}\n",
    "                    auxiliaryRestartData['SCFcount'] = SCFcount\n",
    "                    auxiliaryRestartData['totalIterationCount'] = tree.totalIterationCount\n",
    "                    auxiliaryRestartData['eigenvalues'] = tree.orbitalEnergies\n",
    "                    auxiliaryRestartData['Eold'] = Eold\n",
    "             \n",
    "                    np.save(auxiliaryFile, auxiliaryRestartData)\n",
    "                except FileNotFoundError:\n",
    "                    print('Failed to save restart files.')\n",
    "#                         \n",
    "                        \n",
    "            greenIterationsCount=1\n",
    "\n",
    "            resNorm=1\n",
    "            while resNorm>1e-2:\n",
    "#             for njv in range(10):\n",
    "                targets = tree.extractPhi(m)\n",
    "                sources = tree.extractPhi(m)\n",
    "                weights = np.copy(targets[:,5])\n",
    "                orbitals[:,m] = np.copy(targets[:,3])\n",
    "                \n",
    "            \n",
    "                # Orthonormalize orbital m before beginning Green's iteration\n",
    "                n,M = np.shape(orbitals)\n",
    "                orthWavefunction = modifiedGramSchmidt_singleOrbital(orbitals,weights,m, n, M)\n",
    "                orbitals[:,m] = np.copy(orthWavefunction)\n",
    "                tree.importPhiOnLeaves(orbitals[:,m], m)\n",
    "                psiIn = np.append( np.copy(orbitals[:,m]), tree.orbitalEnergies[m] )\n",
    "#                 psiIn = 1/2*(np.copy(orbitals[:,m]) + np.copy(oldOrbitals[:,m]) )\n",
    "                r = greensIteration_FixedPoint(psiIn)\n",
    "                resNorm = clenshawCurtisNorm(r)\n",
    "                print('CC norm of residual vector: ', resNorm)\n",
    "\n",
    "            \n",
    "            \n",
    "            print('Power iteration tolerance met.  Beginning rootfinding now...') \n",
    "            tol=intraScfTolerance\n",
    "#             tol=2e-7\n",
    "#             if SCFcount==1: \n",
    "#                 tol = 1e-6\n",
    "#             else:\n",
    "#                 tol = 2e-5\n",
    "#             if m>=6:  # tighten the non-degenerate deepest states for benzene.  Just an idea...\n",
    "#                 tol = 2e-5\n",
    "            Done = False\n",
    "#             Done = True\n",
    "#             print('Actually setting Done==True, and not entering fixed point problem.')\n",
    "            while Done==False:\n",
    "                try:\n",
    "                    # Call anderson mixing on the Green's iteration fixed point function\n",
    "                    targets = tree.extractPhi(m)\n",
    "                    sources = tree.extractPhi(m)\n",
    "                    weights = np.copy(targets[:,5])\n",
    "                    orbitals[:,m] = np.copy(targets[:,3])\n",
    "                     \n",
    "                 \n",
    "                    # Orthonormalize orbital m before beginning Green's iteration\n",
    "                    n,M = np.shape(orbitals)\n",
    "                    orthWavefunction = modifiedGramSchmidt_singleOrbital(orbitals,weights,m, n, M)\n",
    "                    orbitals[:,m] = np.copy(orthWavefunction)\n",
    "                    tree.importPhiOnLeaves(orbitals[:,m], m) \n",
    "                     \n",
    "                    psiIn = np.append( np.copy(orbitals[:,m]), tree.orbitalEnergies[m] )\n",
    "#                     print('Calling scipyAnderson')\n",
    "#                     psiOut = scipyAnderson(greensIteration_FixedPoint,psiIn,maxiter=5, alpha=1, M=5, w0=0.01, f_tol=tol, verbose=True, callback=printResidual)\n",
    "                      \n",
    "                       \n",
    "                    ### Anderson Options\n",
    "                    method='anderson'\n",
    "                    jacobianOptions={'alpha':1.0, 'M':5, 'w0':0.01} \n",
    "                    solverOptions={'fatol':tol, 'tol_norm':clenshawCurtisNorm, 'jac_options':jacobianOptions,'maxiter':1000, 'line_search':None, 'disp':True}\n",
    "#                     solverOptions={'fatol':tol, 'tol_norm':eigenvalueNorm, 'jac_options':jacobianOptions,'maxiter':1000, 'line_search':None, 'disp':True}\n",
    "#                     solverOptions={'fatol':tol, 'tol_norm':clenshawCurtisNorm, 'jac_options':jacobianOptions,'maxiter':1000, 'disp':True}\n",
    "# #                     solverOptions={'fatol':1e-6, 'tol_norm':clenshawCurtisNorm, 'jac_options':jacobianOptions, 'disp':True}\n",
    "                     \n",
    "#                     ### Krylov Options\n",
    "# #                     jac = Anderson()\n",
    "#                     jac = BroydenFirst()\n",
    "# #                     kjac = KrylovJacobian(inner_M=InverseJacobian(jac))\n",
    "# #                     jacobianOptions={'method':'lgmres','inner_M':kjac, 'inner_maxiter':3, 'outer_k':2}\n",
    "#                     jacobianOptions={'method':'lgmres','inner_M':InverseJacobian(jac)}\n",
    "# #                     jacobianOptions={'method':'lgmres', 'inner_maxiter':3, 'outer_k':2}\n",
    "#                     method='krylov'\n",
    "# #                     solverOptions={'fatol':tol, 'tol_norm':clenshawCurtisNorm, 'line_search':None, 'disp':True, 'jac_options':jacobianOptions}\n",
    "#                     solverOptions={'fatol':tol, 'tol_norm':clenshawCurtisNorm, 'disp':True, 'jac_options':jacobianOptions}\n",
    "                     \n",
    "                     \n",
    "                    ### Broyden Options\n",
    "#                     method='broyden1'\n",
    "#                     jacobianOptions={'alpha':1.0}\n",
    "# #                     solverOptions={'fatol':1e-6, 'line_search':None, 'disp':True, 'jac_options':jacobianOptions}\n",
    "#                     solverOptions={'fatol':1e-6, 'tol_norm':clenshawCurtisNorm, 'jac_options':jacobianOptions, 'line_search':None, 'disp':True}\n",
    "\n",
    "                    \n",
    "                    print('Calling scipyRoot with %s method' %method)\n",
    "                    sol = scipyRoot(greensIteration_FixedPoint,psiIn, method=method, callback=printResidual, options=solverOptions)\n",
    "                    print(sol.success)\n",
    "                    print(sol.message)\n",
    "                    psiOut = sol.x\n",
    "                    Done = True\n",
    "                except Exception:\n",
    "                    if np.abs(tree.eigenvalueDiff) < tol/10:\n",
    "                        print(\"Rootfinding didn't converge but eigenvalue is converged.  Exiting because this is probably due to degeneracy in the space.\")\n",
    "                        targets = tree.extractPhi(m)\n",
    "                        psiOut = np.append(targets[:,3], tree.orbitalEnergies[m])\n",
    "                        Done=True\n",
    "                    else:\n",
    "                        print('Not converged.  What to do?')\n",
    "                        return\n",
    "            orbitals[:,m] = np.copy(psiOut[:-1])\n",
    "            tree.orbitalEnergies[m] = np.copy(psiOut[-1])\n",
    "             \n",
    "            print('Used %i iterations for wavefunction %i' %(greenIterationsCount,m))\n",
    "\n",
    "\n",
    "\n",
    "#                 if eigenvalueDiff<tol:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     print('Anderson didnt converge, eigenvalue not converged, what to do??  Try again?')\n",
    "#                     targets = tree.extractPhi(m)\n",
    "#                     sources = tree.extractPhi(m)\n",
    "#                     weights = np.copy(targets[:,5])\n",
    "#                     orbitals[:,m] = np.copy(targets[:,3])\n",
    "#                     \n",
    "#                 \n",
    "#                     # Orthonormalize orbital m before beginning Green's iteration\n",
    "#                     n,M = np.shape(orbitals)\n",
    "#                     orthWavefunction = modifiedGramSchmidt_singleOrbital(orbitals,weights,m, n, M) \n",
    "#                     orbitals[:,m] = np.copy(orthWavefunction)\n",
    "#                     tree.importPhiOnLeaves(orbitals[:,m], m) \n",
    "#                     \n",
    "#                     psiIn = np.append( np.copy(orbitals[:,m]), tree.orbitalEnergies[m] )\n",
    "#                     psiOut = scipyAnderson(greensIteration_FixedPoint,psiIn,alpha=1, M=5, w0=0.01, max_iter=30, line_search=None, f_tol=tol, verbose=True, callback=printResidual)\n",
    "\n",
    "\n",
    "#                 targets = tree.extractPhi(m)\n",
    "#                 sources = tree.extractPhi(m)\n",
    "#                 weights = np.copy(targets[:,5])\n",
    "#                 orbitals[:,m] = np.copy(targets[:,3])\n",
    "#                 \n",
    "#             \n",
    "#                 # Orthonormalize orbital m before beginning Green's iteration\n",
    "#                 n,M = np.shape(orbitals)\n",
    "#                 orthWavefunction = modifiedGramSchmidt_singleOrbital(orbitals,weights,m, n, M)\n",
    "#                 orbitals[:,m] = np.copy(orthWavefunction)\n",
    "#                 tree.importPhiOnLeaves(orbitals[:,m], m)\n",
    "#                 psiIn = np.append( np.copy(orbitals[:,m]), tree.orbitalEnergies[m] )\n",
    "# #                 psiIn = 1/2*(np.copy(orbitals[:,m]) + np.copy(oldOrbitals[:,m]) )\n",
    "#                 r = greensIteration_FixedPoint(psiIn)\n",
    "#                 resNorm = clenshawCurtisNorm(r)\n",
    "#                 print('CC norm of residual vector: ', resNorm)\n",
    "                \n",
    "                \n",
    "#             psiOut = scipyAnderson(greensIteration_FixedPoint,psiIn,alpha=1, M=10, w0=0.01,line_search=None,tol_norm=clenshawCurtisNorm, f_tol=1e-4, verbose=True, callback=printResidual)\n",
    "#             psiOut = scipyAnderson(greensIteration_FixedPoint,psiIn,alpha=1, M=10, w0=0.01,line_search=None, f_tol=1e-4, verbose=True, callback=printResidual)\n",
    "#             psiOut = scipyNewtonKrylov(greensIteration_FixedPoint,psiIn, inner_maxiter=4, f_tol=1e-4, tol_norm=clenshawCurtisNorm, verbose=True, callback=printResidual)            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        # sort by energy and compute new occupations\n",
    "        tree.sortOrbitalsAndEnergies()\n",
    "        tree.computeOccupations()\n",
    "        for mm in range(nOrbitals):\n",
    "            # fill in orbitals  \n",
    "            targets = tree.extractPhi(mm)\n",
    "            weights = np.copy(targets[:,5])\n",
    "            oldOrbitals[:,mm] = np.copy(targets[:,3])\n",
    "            orbitals[:,mm] = np.copy(targets[:,3])  \n",
    "#         occupations = computeOccupations(tree.orbitalEnergies, tree.nElectrons, Temperature)\n",
    "        \n",
    "        \n",
    "        ##  DO I HAVE ENOUGH ORBITALS?  CHECK, AND ADD ONE IF NOT.\n",
    "#         if tree.occupations[-1] > 1e-6:\n",
    "#               \n",
    "#             print('Occupation of final state is ', tree.occupations[-1])\n",
    "#             tree.increaseNumberOfWavefunctionsByOne()\n",
    "#             residuals = np.append(residuals, 0.0)\n",
    "#             print('Increased number of wavefunctions to ', tree.nOrbitals)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        print()  \n",
    "        print()\n",
    "\n",
    "\n",
    "        \n",
    "        if maxOrbitals==1:\n",
    "            print('Not updating density or anything since only computing one of the orbitals, not all.')\n",
    "            return\n",
    "        \n",
    "\n",
    "        oldDensity = tree.extractLeavesDensity()\n",
    "        \n",
    "        \n",
    "        \n",
    "        tree.updateDensityAtQuadpoints()\n",
    "         \n",
    "        sources = tree.extractLeavesDensity()  # extract the source point locations.  Currently, these are just all the leaf midpoints\n",
    "        targets = np.copy(sources)\n",
    "        newDensity = np.copy(sources[:,3])\n",
    "        \n",
    "        if SCFcount==1: # not okay anymore because output density gets reset when tolerances get reset.\n",
    "            outputDensities[:,0] = np.copy(newDensity)\n",
    "        else:\n",
    "#             outputDensities = np.concatenate( ( outputDensities, np.reshape(np.copy(newDensity), (numberOfGridpoints,1)) ), axis=1)\n",
    "            \n",
    "            if (SCFcount-1)<mixingHistoryCutoff:\n",
    "                outputDensities = np.concatenate( (outputDensities, np.reshape(np.copy(newDensity), (numberOfGridpoints,1))), axis=1)\n",
    "                print('Concatenated outputDensity.  Now has shape: ', np.shape(outputDensities))\n",
    "            else:\n",
    "                print('Beyond mixingHistoryCutoff.  Replacing column ', (SCFcount-1)%mixingHistoryCutoff)\n",
    "#                                 print('Shape of oldOrbitals[:,m]: ', np.shape(oldOrbitals[:,m]))\n",
    "                outputDensities[:,(SCFcount-1)%mixingHistoryCutoff] = newDensity\n",
    "        \n",
    "#         print('Sample of output densities:')\n",
    "#         print(outputDensities[0,:])    \n",
    "        integratedDensity = np.sum( newDensity*weights )\n",
    "        densityResidual = np.sqrt( np.sum( (sources[:,3]-oldDensity[:,3])**2*weights ) )\n",
    "        print('Integrated density: ', integratedDensity)\n",
    "        print('Density Residual ', densityResidual)\n",
    "        \n",
    "#         densityResidual = np.sqrt( np.sum( (outputDensities[:,SCFcount-1] - inputDensities[:,SCFcount-1])**2*weights ) )\n",
    "#         print('Density Residual from arrays ', densityResidual)\n",
    "        print('Shape of density histories: ', np.shape(outputDensities), np.shape(inputDensities))\n",
    "        \n",
    "        # Now compute new mixing with anderson scheme, then import onto tree. \n",
    "      \n",
    "        \n",
    "        if mixingScheme == 'Simple':\n",
    "            print('Using simple mixing, from the input/output arrays')\n",
    "            simpleMixingDensity = mixingParameter*inputDensities[:,SCFcount-1] + (1-mixingParameter)*outputDensities[:,SCFcount-1]\n",
    "            integratedDensity = np.sum( simpleMixingDensity*weights )\n",
    "            print('Integrated simple mixing density: ', integratedDensity)\n",
    "            tree.importDensityOnLeaves(simpleMixingDensity)\n",
    "        \n",
    "        elif mixingScheme == 'Anderson':\n",
    "            print('Using anderson mixing.')\n",
    "            andersonDensity = densityMixing.computeNewDensity(inputDensities, outputDensities, mixingParameter,weights)\n",
    "            integratedDensity = np.sum( andersonDensity*weights )\n",
    "            print('Integrated anderson density: ', integratedDensity)\n",
    "            tree.importDensityOnLeaves(andersonDensity)\n",
    "        \n",
    "        elif mixingScheme == 'None':\n",
    "            pass # don't touch the density\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            print('Mixing must be set to either Simple, Anderson, or None')\n",
    "            return\n",
    "            \n",
    "\n",
    " \n",
    "        \"\"\" \n",
    "        Compute new electron-electron potential and update pointwise potential values \n",
    "        \"\"\"\n",
    "#         starthartreeConvolutionTime = timer()\n",
    "\n",
    "        density_sources = tree.extractLeavesDensity()  # extract the source point locations.  Currently, these are just all the leaf midpoints\n",
    "        density_targets = np.copy(sources)\n",
    "        \n",
    "        if GPUpresent==True:\n",
    "            if treecode==False:\n",
    "                V_hartreeNew = np.zeros((len(targets)))\n",
    "                gpuHartreeGaussianSingularitySubract[blocksPerGrid, threadsPerBlock](targets,density_sources,V_hartreeNew,alphasq)\n",
    "            elif treecode==True:\n",
    "                numTargets = len(density_targets)\n",
    "                numSources = len(density_sources)\n",
    "                sourceX = np.copy(density_sources[:,0])\n",
    "    \n",
    "                sourceY = np.copy(density_sources[:,1])\n",
    "                sourceZ = np.copy(density_sources[:,2])\n",
    "                sourceValue = np.copy(density_sources[:,3])\n",
    "                sourceWeight = np.copy(density_sources[:,4])\n",
    "                \n",
    "                targetX = np.copy(density_targets[:,0])\n",
    "                targetY = np.copy(density_targets[:,1])\n",
    "                targetZ = np.copy(density_targets[:,2])\n",
    "                targetValue = np.copy(density_targets[:,3])\n",
    "                targetWeight = np.copy(density_targets[:,4])\n",
    "                \n",
    "                start = time.time()\n",
    "                potentialType=2 \n",
    "#                 alpha = gaussianAlpha\n",
    "                V_hartreeNew = treecodeWrappers.callTreedriver(numTargets, numSources, \n",
    "                                                               targetX, targetY, targetZ, targetValue, \n",
    "                                                               sourceX, sourceY, sourceZ, sourceValue, sourceWeight,\n",
    "                                                               potentialType, gaussianAlpha, treecodeOrder, theta, maxParNode, batchSize)\n",
    "                print('Convolution time: ', time.time()-start)\n",
    "                \n",
    "        elif GPUpresent==False:\n",
    "            \n",
    "            sourceX = np.copy(density_sources[:,0])\n",
    "            sourceY = np.copy(density_sources[:,1])\n",
    "            sourceZ = np.copy(density_sources[:,2])\n",
    "            sourceValue = np.copy(density_sources[:,3])\n",
    "            sourceWeight = np.copy(density_sources[:,4])\n",
    "            \n",
    "            targetX = np.copy(density_targets[:,0])\n",
    "            targetY = np.copy(density_targets[:,1])\n",
    "            targetZ = np.copy(density_targets[:,2])\n",
    "            targetValue = np.copy(density_targets[:,3])\n",
    "            targetWeight = np.copy(density_targets[:,4])\n",
    "                \n",
    "            if treecode==False:\n",
    "                V_hartreeNew = directSumWrappers.callCompiledC_directSum_PoissonSingularitySubtract(numTargets, numSources, alphasq, \n",
    "                                                                                                  targetX, targetY, targetZ, targetValue,targetWeight, \n",
    "                                                                                                  sourceX, sourceY, sourceZ, sourceValue, sourceWeight)\n",
    "\n",
    "                V_hartreeNew += density_targets[:,3]* (4*np.pi)/ alphasq/ 2   # Correct for exp(-r*r/alphasq)  # DONT TRUST\n",
    "\n",
    "                \n",
    "            else:\n",
    "                potentialType=2 # shoud be 0.  Set to 1, 2, or 3 just to test other kernels quickly\n",
    "                print('NEED TREECODE PARAMS FOR THIS SECTION')\n",
    "                return\n",
    "#                 order=3\n",
    "#                 theta = 0.5\n",
    "#                 maxParNode = 500\n",
    "#                 batchSize = 500\n",
    "#                 alphasq = gaussianAlpha**2\n",
    "#                 V_hartreeNew = treecodeWrappers.callTreedriver(numTargets, numSources, \n",
    "#                                                                targetX, targetY, targetZ, targetValue, \n",
    "#                                                                sourceX, sourceY, sourceZ, sourceValue, sourceWeight,\n",
    "#                                                                potentialType, alphasq, order, theta, maxParNode, batchSize)\n",
    "#                 if potentialType==2:\n",
    "#                     V_hartreeNew += density_targets[:,3]* (4*np.pi) / alphasq/2\n",
    "        \n",
    "        else:\n",
    "            print('Is GPUpresent supposed to be true or false?')\n",
    "            return\n",
    "      \n",
    "        tree.importVhartreeOnLeaves(V_hartreeNew)\n",
    "        tree.updateVxcAndVeffAtQuadpoints()\n",
    "#         hartreeConvolutionTime = timer() - starthartreeConvolutionTime\n",
    "#         print('Computing Vhartree and updating Veff took:    %.4f seconds. ' %hartreeConvolutionTime)\n",
    "\n",
    "        \n",
    "        \"\"\" \n",
    "        Compute the new orbital and total energies \n",
    "        \"\"\"\n",
    " \n",
    "        tree.updateTotalEnergy(gradientFree=gradientFree) \n",
    "        print('Band energies after Veff update: %1.6f H, %1.2e H'\n",
    "              %(tree.totalBandEnergy, tree.totalBandEnergy-Eband))\n",
    "        print('Orbital Energy Errors after Veff Update: ', tree.orbitalEnergies-referenceEigenvalues[:tree.nOrbitals]-tree.gaugeShift)\n",
    "        \n",
    "        for m in range(tree.nOrbitals):\n",
    "            print('Orbital %i error: %1.3e' %(m, tree.orbitalEnergies[m]-referenceEigenvalues[m]-tree.gaugeShift))\n",
    "        \n",
    "        \n",
    "        energyResidual = abs( tree.E - Eold )  # Compute the energyResidual for determining convergence\n",
    "        Eold = np.copy(tree.E)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Print results from current iteration\n",
    "        \"\"\"\n",
    "\n",
    "        print('Orbital Energies: ', tree.orbitalEnergies) \n",
    "\n",
    "        print('Updated V_x:                           %.10f Hartree' %tree.totalVx)\n",
    "        print('Updated V_c:                           %.10f Hartree' %tree.totalVc)\n",
    "        \n",
    "        print('Updated Band Energy:                   %.10f H, %.10e H' %(tree.totalBandEnergy, tree.totalBandEnergy-Eband) )\n",
    "#         print('Updated Kinetic Energy:                 %.10f H, %.10e H' %(tree.totalKinetic, tree.totalKinetic-Ekinetic) )\n",
    "        print('Updated E_Hartree:                      %.10f H, %.10e H' %(tree.totalEhartree, tree.totalEhartree-Ehartree) )\n",
    "        print('Updated E_x:                           %.10f H, %.10e H' %(tree.totalEx, tree.totalEx-Eexchange) )\n",
    "        print('Updated E_c:                           %.10f H, %.10e H' %(tree.totalEc, tree.totalEc-Ecorrelation) )\n",
    "#         print('Updated totalElectrostatic:            %.10f H, %.10e H' %(tree.totalElectrostatic, tree.totalElectrostatic-Eelectrostatic))\n",
    "        print('Total Energy:                          %.10f H, %.10e H' %(tree.E, tree.E-Etotal))\n",
    "        print('Energy Residual:                        %.3e' %energyResidual)\n",
    "        print('Density Residual:                       %.3e\\n\\n'%densityResidual)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "#         if vtkExport != False:\n",
    "#             filename = vtkExport + '/mesh%03d'%(SCFcount-1) + '.vtk'\n",
    "#             tree.exportGridpoints(filename)\n",
    "\n",
    "        printEachIteration=True\n",
    "\n",
    "        if printEachIteration==True:\n",
    "            header = ['Iteration', 'densityResidual', 'orbitalEnergies','bandEnergy', 'kineticEnergy', \n",
    "                      'exchangeEnergy', 'correlationEnergy', 'hartreeEnergy', 'totalEnergy']\n",
    "        \n",
    "            myData = [SCFcount, densityResidual, tree.orbitalEnergies, tree.totalBandEnergy, tree.totalKinetic, \n",
    "                      tree.totalEx, tree.totalEc, tree.totalEhartree, tree.E]\n",
    "            \n",
    "        \n",
    "            if not os.path.isfile(SCFiterationOutFile):\n",
    "                myFile = open(SCFiterationOutFile, 'a')\n",
    "                with myFile:\n",
    "                    writer = csv.writer(myFile)\n",
    "                    writer.writerow(header) \n",
    "                \n",
    "            \n",
    "            myFile = open(SCFiterationOutFile, 'a')\n",
    "            with myFile:\n",
    "                writer = csv.writer(myFile)\n",
    "                writer.writerow(myData)\n",
    "        \n",
    "        \n",
    "        ## Write the restart files\n",
    "        \n",
    "        # save arrays \n",
    "        try:\n",
    "            np.save(wavefunctionFile, orbitals)\n",
    "            \n",
    "            sources = tree.extractLeavesDensity()\n",
    "            np.save(densityFile, sources[:,3])\n",
    "            np.save(outputDensityFile, outputDensities)\n",
    "            np.save(inputDensityFile, inputDensities)\n",
    "            \n",
    "            np.save(vHartreeFile, V_hartreeNew)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # make and save dictionary\n",
    "            auxiliaryRestartData = {}\n",
    "            auxiliaryRestartData['SCFcount'] = SCFcount\n",
    "            auxiliaryRestartData['totalIterationCount'] = tree.totalIterationCount\n",
    "            auxiliaryRestartData['eigenvalues'] = tree.orbitalEnergies\n",
    "            auxiliaryRestartData['Eold'] = Eold\n",
    "    \n",
    "            np.save(auxiliaryFile, auxiliaryRestartData)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "                \n",
    "        \n",
    "        if plotSliceOfDensity==True:\n",
    "#             densitySliceSavefile = densityPlotsDir+'/iteration'+str(SCFcount)\n",
    "            r, rho = tree.interpolateDensity(xi,yi,zi,xf,yf,zf, numpts, plot=False, save=False)\n",
    "        \n",
    "#\n",
    "            densities = np.load(densitySliceSavefile+'.npy')\n",
    "            densities = np.concatenate( (densities, np.reshape(rho, (numpts,1))), axis=1)\n",
    "            np.save(densitySliceSavefile,densities)\n",
    "    \n",
    "                \n",
    "        \"\"\" END WRITING INDIVIDUAL ITERATION TO FILE \"\"\"\n",
    "     \n",
    "        \n",
    "        if tree.E > 0.0:                       # Check that the current guess for energy didn't go positive.  Reset it if it did. \n",
    "            print('Warning, Energy is positive')\n",
    "            tree.E = -0.5\n",
    "            \n",
    "        \n",
    "        if SCFcount >= 150:\n",
    "            print('Setting density residual to -1 to exit after the 150th SCF')\n",
    "            densityResidual = -1\n",
    "            \n",
    "#         if SCFcount >= 1:\n",
    "#             print('Setting density residual to -1 to exit after the First SCF just to test treecode or restart')\n",
    "#             energyResidual = -1\n",
    "#             densityResidual = -1\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    print('\\nConvergence to a tolerance of %f took %i iterations' %(interScfTolerance, SCFcount))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Cell\n",
    "n=1\n",
    "domainSize          = 20\n",
    "minDepth            = 3\n",
    "maxDepth            = 20\n",
    "additionalDepthAtAtoms= 0\n",
    "order               = 5\n",
    "subtractSingularity = 1\n",
    "smoothingEps        = 0\n",
    "gaussianAlpha       = 1.0\n",
    "gaugeShift          = -0.5\n",
    "divideCriterion     = 'LW5'\n",
    "divideParameter1    = 500\n",
    "divideParameter2    = 0\n",
    "divideParameter3    = 0\n",
    "divideParameter4    = 0\n",
    "energyTolerance     = 1e-7\n",
    "scfTolerance        = 5e-6\n",
    "outputFile          = \"/home/njvaughn/synchronizedDataFiles/jupyterTest/meshparam1_%1.2e.csv\" %divideParameter1\n",
    "inputFile           = '../src/utilities/molecularConfigurations/berylliumAuxiliary.csv'\n",
    "vtkDir              = 'None'\n",
    "noGradients         = True\n",
    "symmetricIteration  = False\n",
    "mixingScheme        = 'Anderson'\n",
    "mixingParameter     = 0.5\n",
    "mixingHistoryCutoff = 20\n",
    "GPUpresent          = True\n",
    "treecode            = False\n",
    "treecodeOrder       = 0\n",
    "theta               = 0\n",
    "maxParNode          = 8000\n",
    "batchSize           = 8000\n",
    "base                = 1\n",
    "restart             = False\n",
    "savedMesh           = ''\n",
    "\n",
    "\n",
    "tree = setUpTree()  \n",
    "testGreenIterationsGPU_rootfinding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
